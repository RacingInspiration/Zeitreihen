{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Vorverarbeitung in der Praxis (Kapitel 3.4.4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1) Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T11:24:14.738040Z",
     "start_time": "2024-11-11T11:24:14.727115Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('insurance.csv')\n",
    "df['region'].unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['southwest', 'southeast', 'northwest', 'northeast'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Teil 1 - Anlernprozess durchführen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### a) Trainings- und Testdaten separieren"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T11:24:14.841359Z",
     "start_time": "2024-11-11T11:24:14.816372Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['age', 'sex', 'bmi', 'children', 'smoker', 'region']]\n",
    "y = df['charges']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                   test_size=0.2, random_state=11)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (268, 6), (1070,), (268,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### b) Kategoriale Variablen aus Trainingsdaten ziehen, mit dem OneHotEncoder anlernen und transformieren"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T11:24:14.924056Z",
     "start_time": "2024-11-11T11:24:14.916683Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X_train_ohe = X_train[['sex', 'smoker', 'region']]\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "X_train_ohe = ohe.fit_transform(X_train_ohe)\n",
    "X_train_ohe"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 1., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 1.],\n",
       "       [0., 1., 1., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 1., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 1., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### c) Numerische Variablen aus Trainingsdaten extrahieren, den Standardisierer anlernen, die Daten transformieren"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T11:24:15.053437Z",
     "start_time": "2024-11-11T11:24:15.028782Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_std = X_train[['age', 'bmi', 'children']]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train_std)\n",
    "X_train_std.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### d) Die beiden separierten Arrays wieder zusammenführen, um sie der fit-Methode des Regressors zum Anlernen zu übergeben"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T11:24:15.138187Z",
     "start_time": "2024-11-11T11:24:15.131253Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "X_train_compl = np.concatenate([X_train_ohe, X_train_std], axis=1)\n",
    "X_train_compl.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 11)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### e) Den angelernten OneHotEncoder und den angelernten Standardisierer abspeichern"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T11:24:15.204533Z",
     "start_time": "2024-11-11T11:24:15.197988Z"
    }
   },
   "source": [
    "import joblib\n",
    "joblib.dump(ohe, 'ohe.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Modell mit vorbereiteten Daten anlernen und angelerntes Modell abspeichern"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T11:24:15.320058Z",
     "start_time": "2024-11-11T11:24:15.294850Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_compl, y_train)\n",
    "joblib.dump(model, 'model.pkl')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Teil II: Objektorientierter Ansatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### a) Klasse erzeugen, die die Vorverarbeitung und den Schätzprozess übernimmt"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T11:24:15.363968Z",
     "start_time": "2024-11-11T11:24:15.357666Z"
    }
   },
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "class PredictInsurance():\n",
    "    \n",
    "    def __init__(self, ohe: str, scaler: str, model: str,\n",
    "                ohe_cols=['sex', 'smoker', 'region'],\n",
    "                scale_cols=['age', 'bmi', 'children']):\n",
    "        self.ohe = self.__load_file(ohe)\n",
    "        self.scaler = self.__load_file(scaler)\n",
    "        self.model = self.__load_file(model)\n",
    "        self.ohe_cols = ohe_cols\n",
    "        self.scale_cols = scale_cols\n",
    "\n",
    "    def predict(self, X_pred: pd.DataFrame) -> np.array:\n",
    "        X_compl = self.__preprocess(X_pred)\n",
    "        return self.model.predict(X_compl)\n",
    "\n",
    "    def evaluate(self, X_pred: pd.DataFrame, y_true: pd.Series) -> float:\n",
    "        y_pred = self.predict(X_pred)\n",
    "        return (mean_absolute_error(y_true, y_pred),\n",
    "                    r2_score(y_true, y_pred))\n",
    "\n",
    "    def __load_file(self, file):\n",
    "        return joblib.load(file)\n",
    "    \n",
    "    def __preprocess(self, X_pred):\n",
    "        X_ohe = self.__ohe(X_pred[self.ohe_cols])\n",
    "        X_std = self.__scale(X_pred[self.scale_cols])\n",
    "        return np.concatenate([X_ohe, X_std], axis=1)\n",
    "\n",
    "    def __ohe(self, X_ohe):\n",
    "        return self.ohe.transform(X_ohe)\n",
    "\n",
    "    def __scale(self, X_std):\n",
    "        return self.scaler.transform(X_std)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4) Evaluation durchführen"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T11:24:15.413018Z",
     "start_time": "2024-11-11T11:24:15.403876Z"
    }
   },
   "source": [
    "predictor = PredictInsurance( ohe='ohe.pkl', \n",
    "                              scaler='scaler.pkl',\n",
    "                              model='model.pkl')\n",
    "mae, r_square = predictor.evaluate(X_test, y_test)\n",
    "print('mae: {:.3f}, r2: {:.3f}'.format(mae, r_square))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 3798.304, r2: 0.801\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 5) Schätzung durchführen (Beispieldatensatz)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-11T11:24:15.522554Z",
     "start_time": "2024-11-11T11:24:15.512797Z"
    }
   },
   "source": [
    "X_pred = pd.DataFrame([[35, 'female', 25.77, 1, 'no', 'southeast']],\n",
    "   columns=['age', 'sex', 'bmi', 'children', 'smoker', 'region'])\n",
    "y_pred = predictor.predict(X_pred)\n",
    "print('prediction (X_pred): {:.3f}'.format(y_pred[0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction (X_pred): 5408.000\n"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
